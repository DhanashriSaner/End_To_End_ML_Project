

<h1>Car Price Prediction Project</h1>

<details><summary> <h2> Step 1 : Data Preprocessing </h2> </summary>
<p>
<strong> Step 1 : Data Cleaning </strong>
  <ol>
  <li>Filling Missing Values</li>
  <li>Remove Duplicate Or Unnecessary Data</li>
  <li>Label Consistency</li>
  </ol> 
<strong> Step 2 : Outlier Detection </strong><br>
  Below are the methods to detect the outliers
  <ol>
  <li>Boxplots <a href="https://towardsdatascience.com/boxplot-for-anomaly-detection-9eac783382fd"> YouTube Video </a></li>
  <li>Z-score  <a href="https://www.youtube.com/watch?v=KFuEAGR3HS4&t=1063s"> YoutTube Video</a></li>
  <li>Inter Quantile Range(IQR) <a href="https://www.youtube.com/watch?v=A3gClkblXK8"> YoutTube Video</a></li>
  </ol> 
  Below are methods to treat the outliers
  <ol>
  <li>Remove the outliers</li>
  <li>Mean/Median imputation</li>
  <li>Quantile based flooring & capping</li>
  <li>Insensitive Machine Learning Models</li>
  </ol> 
  <strong> Step 3 : Feature Encoding </strong><br>
  Encondig are of 3 types: Binary, Ordinal, Nominal <a href="https://www.geeksforgeeks.org/feature-encoding-techniques-machine-learning/">Refer This Blog</a>
  <ol>
  <li>Label Encoding</li>
  <li>Oridinal Encoding <a href="https://datascience.stackexchange.com/questions/39317/difference-between-ordinalencoder-and-labelencoder"> Must Read </a> </li>
  <li>One Hot Encoding</li>
  <li>Frequency Encoding</li>
  <li>Mean/Target Encoding</li>
  </ol> 
</p>
</details>

<details><summary> <h2> Step 2 : Exploratory Data Analysis </h2> </summary>

</details>

<details><summary> <h2> Step 3 : Feature Engineering </h2> </summary>

</details>

<details><summary> <h2> Step 4 : Model Building </h2> </summary>

</details>

<details><summary> <h2> Step 5 : Model Evaluation And Inference </h2> </summary>
</details>

<details><summary> <h2> Step 6 : Model Deployment</h2> </summary>
</details>
